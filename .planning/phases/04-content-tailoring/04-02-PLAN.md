---
phase: 04-content-tailoring
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - cmd/optimize_test.go
autonomous: true

must_haves:
  truths:
    - "Tests verify optimize command handles missing application folder"
    - "Tests verify optimize command handles missing config"
    - "Tests verify optimize command handles missing job description"
    - "Tests verify optimize command writes versioned output"
    - "Tests verify --ats flag selects correct prompt"
    - "Tests verify -m flag passes model to executor"
  artifacts:
    - path: "cmd/optimize_test.go"
      provides: "Comprehensive test coverage for optimize command"
      min_lines: 150
  key_links:
    - from: "cmd/optimize_test.go"
      to: "cmd/optimize.go"
      via: "Tests newOptimizeCommand and error paths"
      pattern: "newOptimizeCommand|TestOptimize"
---

<objective>
Create comprehensive tests for the optimize command covering all error paths and successful execution.

Purpose: Ensure the optimize command handles edge cases correctly - missing files, missing config, flag combinations - and produces correct output. Tests use mock executor pattern established in apply_test.go.

Output: Passing test suite in cmd/optimize_test.go covering error paths and success cases.
</objective>

<execution_context>
@/home/claude/.claude/get-shit-done/workflows/execute-plan.md
@/home/claude/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-content-tailoring/04-RESEARCH.md

# Plan 01 must complete first
@.planning/phases/04-content-tailoring/04-01-PLAN.md

# Test patterns to follow
@cmd/apply_test.go
@internal/application/versioning_test.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create optimize command tests</name>
  <files>cmd/optimize_test.go</files>
  <action>
Create `cmd/optimize_test.go` following the test patterns from apply_test.go and versioning_test.go:

1. **Test helper setup:**
   ```go
   func setupOptimizeTest(t *testing.T) (string, func()) {
       t.Helper()
       tmpDir := t.TempDir()
       origDir, _ := os.Getwd()
       os.Chdir(tmpDir)
       return tmpDir, func() { os.Chdir(origDir) }
   }
   ```

2. **TestOptimizeCommand_MissingAppFolder:**
   - Don't create applications/test-app folder
   - Run optimize test-app
   - Expect error containing "application folder not found"

3. **TestOptimizeCommand_MissingConfig:**
   - Create applications/test-app folder with job.txt
   - Don't create m2cv.yml
   - Run optimize test-app
   - Expect error containing "m2cv.yml not found"

4. **TestOptimizeCommand_MissingJobDescription:**
   - Create applications/test-app folder (empty)
   - Create m2cv.yml with base_cv_path
   - Create base CV file
   - Run optimize test-app
   - Expect error containing "no .txt file found"

5. **TestOptimizeCommand_MissingBaseCV:**
   - Create applications/test-app with job.txt
   - Create m2cv.yml pointing to nonexistent base CV
   - Run optimize test-app
   - Expect error containing "failed to read base CV"

6. **TestOptimizeCommand_Success (integration with mock executor):**
   - This test needs to mock ClaudeExecutor to avoid calling real Claude
   - Create a test-specific version that injects a mock
   - Or, test the error paths only and rely on manual E2E testing for success

   Alternative approach - test just the wiring by checking the command structure:
   ```go
   func TestOptimizeCommand_Structure(t *testing.T) {
       cmd := newOptimizeCommand()

       // Verify command structure
       if cmd.Use != "optimize <application-name>" {
           t.Errorf("wrong Use: %s", cmd.Use)
       }

       // Verify flags exist
       if cmd.Flags().Lookup("model") == nil {
           t.Error("missing --model flag")
       }
       if cmd.Flags().Lookup("ats") == nil {
           t.Error("missing --ats flag")
       }
   }
   ```

7. **TestOptimizeCommand_ATSPromptSelection:**
   - This tests the prompt selection logic
   - Can verify by checking assets.GetPrompt("optimize-ats") returns different content than "optimize"
   - Tests the conditional path in the command

8. **TestOptimizeCommand_ModelOverride:**
   - Test that model flag is properly bound
   - Can check flag default is empty string
   - Full integration would need mock executor

**Test patterns to use:**
- Use t.Parallel() where tests don't share state
- Use t.TempDir() for filesystem isolation
- Disable preflight checks: `rootCmd.PersistentPreRunE = nil`
- Table-driven tests where applicable
- Error message assertions with strings.Contains

**Important:** For tests that would call Claude, either:
a. Mock the executor (requires refactoring to inject it)
b. Skip those tests in short mode
c. Test only the error paths that happen before Claude is called

For this plan, focus on error path tests that verify the command catches problems early (missing folder, missing config, missing files) - these don't require mocking Claude.
  </action>
  <verify>
Run `go test ./cmd/... -v` - all tests pass.
Run `go test ./cmd/... -race` - no race conditions.
  </verify>
  <done>
cmd/optimize_test.go exists with tests covering:
- Command structure (Use, flags)
- Missing application folder error
- Missing config error
- Missing job description error
- Missing base CV error
All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify full build and test suite</name>
  <files></files>
  <action>
Run the complete test and build suite to ensure nothing is broken:

1. `go build ./...` - full build
2. `go test ./...` - all tests including new optimize tests
3. `go vet ./...` - static analysis
4. `./m2cv optimize --help` - verify CLI works

If any failures occur, fix them before completing the plan.
  </action>
  <verify>
All commands exit with status 0:
- go build ./...
- go test ./...
- go vet ./...
  </verify>
  <done>
Full test suite passes, build succeeds, no vet warnings.
  </done>
</task>

</tasks>

<verification>
1. `go test ./cmd/... -v` shows optimize tests passing
2. `go test ./... -race` passes (no races)
3. `go build ./...` succeeds
4. `go vet ./...` clean
5. Test coverage includes error paths for optimize command
</verification>

<success_criteria>
- cmd/optimize_test.go exists with 5+ test functions
- Tests cover: command structure, missing app folder, missing config, missing job desc, missing base CV
- All tests pass
- Full project build and test suite passes
</success_criteria>

<output>
After completion, create `.planning/phases/04-content-tailoring/04-02-SUMMARY.md`
</output>
